model:
  encoder:
    type: bi-sequence
    output-dim: 24
    output-dropout: 0.0
    word-embedding-size: 24
    word-embedding-dropout: 0.0
    sequence-type: lstm
    sequence-dropout: 0.0
    sequence-layers: 2
  decoder:
    type: sequence
    output-dim: 24
    output-dropout: 0.0
    word-embedding-size: 24
    word-embedding-dropout: 0.0
    init-with-source: average
    sequence-type: lstm
    sequence-dropout: 0.0
    sequence-layers: 2
  glue:
    h-prime-size: 24
    input-feeding: true
    attention-type: dot

trainer:
  type: Adam
  init-learning-rate: 0.02
  gradient-clipping: true
  decay-learning-rate: false
  mini-batch-size: 2
  reporting-frequency: 10
  validation-frequency: 50

words:
  source:
    min-count: 0
    max-vocab: 50000
    max-sent-length: 100
  target:
    min-count: 0
    max-vocab: 50000
    max-sent-length: 100
    bytepairs: 16000

validation:
  beam-search:
    word-penalty: 1.0
    beam-size: 12
  metric: bleu
  weight-decay: 0
  sparse-update: false
